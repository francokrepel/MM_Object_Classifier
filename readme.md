# Multimodal Object Classifier

This repository hosts the development and implementation of a Multimodal Object Classifier which leverages data from the Amazon Berkley dataset. The classifier is designed to efficiently categorize objects into distinct classes based on the provided multimodal data. This project is a stride towards understanding and exploiting the synergy between different modalities to improve object classification.

## Dataset and Metadata

The core data for this project is sourced from the Amazon Berkley dataset. In addition, metadata that provides further insights into the data is crucial for the robust performance of our classifier. This metadata is meticulously organized and stored securely in a Google Drive folder. Access to the metadata can be provided upon request to interested parties for a deeper understanding or for collaborative efforts.

## Repository Structure

- `Object_Classification.ipynb`: This Jupyter Notebook contains the code for the Multimodal Object Classifier. It includes data preprocessing, model architecture, training, evaluation, and inference sections.

## Getting Started

1. Clone this repository to your local machine.
```bash
git clone https://github.com/francokrepel/MM_Object_Classifier.git
```
2. Navigate to the cloned repository.
```bash
cd MM_Object_Classifier
```
3. Open the Object_Classification.ipynb notebook in a Jupyter environment to view and run the code.
```bash
jupyter notebook Object_Classification.ipynb
```
4. Requesting Metadata Access
To request access to the metadata, send me a message and I can share the google drive folder link with you
